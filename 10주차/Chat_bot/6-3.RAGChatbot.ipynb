{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#**RAG Chatbot**\n","#### **PDF 파일의 정보를 추출하고 RAG 기법을 사용하여 이 정보를 LLM이 활용하는 챗봇 만들기**"],"metadata":{"id":"hVzYd_OY0B7W"}},{"cell_type":"markdown","source":["##**1. 환경 준비**"],"metadata":{"id":"hRH8NNb7jjh4"}},{"cell_type":"markdown","source":["#### (1) 구글 드라이브 연결"],"metadata":{"id":"B-Ste0-ij1SR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bknf5IL_sLuJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724122515259,"user_tz":-540,"elapsed":3285,"user":{"displayName":"허신 - Business Intelligence","userId":"11511914061488776232"}},"outputId":"f535a1d2-4bbc-4d49-8225-4c734f831c69"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# 구글 드라이브를 코랩 환경에 연결하여 파일을 저장하거나 읽을 수 있도록 설정\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#### (2) 라이브러리 설치"],"metadata":{"id":"oMhy5LjDkD6i"}},{"cell_type":"code","source":["!pip install streamlit -q\n","!pip install pyngrok -q\n","!pip install openai -q\n","!pip install langchain -q\n","!pip install -U langchain-community -q\n","!pip install sentence-transformers -q\n","!pip install faiss-gpu -q\n","!pip install pyPDF2 -q"],"metadata":{"id":"ghrkopImsLuJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**2. 코딩**"],"metadata":{"id":"QQ1em3XukUiQ"}},{"cell_type":"code","source":["# 이 파일에 Streamlit 애플리케이션 코드를 작성\n","# 코드 수정 후, 셀을 실행해야 변경된 내용이 ooo.py 파일이 적용됨\n","%%writefile /content/drive/MyDrive/Streamlit/6-3.RAGChatbot.py\n","\n","# 라이브러리 불러오기\n","import streamlit as st\n","from PyPDF2 import PdfReader\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.embeddings import OpenAIEmbeddings, SentenceTransformerEmbeddings\n","from langchain.vectorstores import FAISS\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n","from langchain.memory import ConversationBufferWindowMemory\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# PDF 문서에서 텍스트 추출 함수 정의하기\n","def get_pdf_text(pdf_docs):\n","    text = \"\"\n","    for\n","        pdf_reader\n","        for\n","            text\n","    return text\n","\n","# 텍스트 분할 함수 정의하기\n","def get_text_chunks(text):\n","    text_splitter = RecursiveCharacterTextSplitter(\n","\n","    )\n","    chunks =\n","    return chunks\n","\n","# 임베딩 생성 & 벡터 저장소 생성 함수 정의하기\n","def get_vectorstore(text_chunks):\n","    embeddings = SentenceTransformerEmbeddings()\n","    vectorstore = FAISS.from_texts()\n","    return vectorstore\n","\n","# openai 키 입력\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxx\"\n","\n","# 주어진 벡터 저장소로 대화 체인 생성 함수 정의하기\n","def get_conversation_chain(vectorstore):\n","    memory = ConversationBufferWindowMemory(\n","    conversation_chain = ConversationalRetrievalChain.from_llm(\n","        llm=ChatOpenAI(\n","        retriever=vectorstore.as_retriever(),\n","\n","\n","    )\n","    return conversation_chain\n","\n","# PDF 파일을 업로드하고 텍스트를 추출하여 AI 대화 준비하기\n","user_uploads =\n","if\n","    with\n","        raw_text =\n","        text_chunks =\n","        vectorstore =\n","        st.session_state.conversation =\n","\n","# 사용자의 질문에 AI가 답변하기\n","if user_query :=\n","    if 'conversation' in st.session_state:\n","        result = st.session_state.conversation({\n","\n","\n","        })\n","        response =\n","    else:\n","        response =\n","    with st.chat_message\n"],"metadata":{"id":"-090Z7oHKkEe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724122556742,"user_tz":-540,"elapsed":828,"user":{"displayName":"허신 - Business Intelligence","userId":"11511914061488776232"}},"outputId":"a7f95fad-d751-45a3-d67c-26b564935763"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/Streamlit/6-3.RAGChatbot.py\n"]}]},{"cell_type":"markdown","source":["##**3. Streamlit 실행**\n","* **ngrok 인증 토큰 받는 방법**\n","    * ngrok.com 사이트 가입 (Sign up)\n","    * 좌측 Getting Started > Your Authtoken 메뉴 선택하여 토큰 번호 받음\n","    * ngrok은 인터넷으로 터널을 만들어 로컬 개발 환경의 포트를 개방하고 애플리케이션의 외부 접근을 도와주는 터널 프로그램\n","*   **ooo.py 파일을 수정했는 데 이전 결과가 그대로 나타남**  \n","    * 코드 수정 후, 셀을 실행해야 변경된 내용이 ooo.py 파일이 적용됨\n","\n","* **아래 셀 실행결과가 아래와 같이 나타나면 좌측 url 주소(& <U>Visit Site 버튼</U> 클릭) 선택하여 결과 확인**\n","    * NgrokTunnel: \"https://5c10-34-86-195-94.ngrok-free.app\" -> \"http://localhost:8501\""],"metadata":{"id":"IJ0kr5inr0Gn"}},{"cell_type":"code","source":["from pyngrok import ngrok\n","\n","# ngrok 인증 토큰을 설정\n","ngrok.set_auth_token(\"ngrok 인증토큰번호를 입력하세요\")\n","\n","# Streamlit 애플리케이션을 백그라운드에서 실행\n","# ngrok을 통해 외부에서 접근 가능한 URL을 생성\n","!streamlit run /content/drive/MyDrive/Streamlit/6-3.RAGChatbot.py&>/dev/null&\n","url = ngrok.connect( addr='8501' )\n","print(url)"],"metadata":{"id":"Q76Q9fuhbhqD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724122666506,"user_tz":-540,"elapsed":983,"user":{"displayName":"허신 - Business Intelligence","userId":"11511914061488776232"}},"outputId":"1a6701ad-daff-4f44-ad0e-bd55737f9fd9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NgrokTunnel: \"https://64f7-35-194-209-126.ngrok-free.app\" -> \"http://localhost:8501\"\n"]}]},{"cell_type":"markdown","source":["###**참조)**"],"metadata":{"id":"fniWUPvbr4Bg"}},{"cell_type":"code","source":["# 실행 중인 세션 확인\n","!ps"],"metadata":{"id":"8EhoB-Kir4Bh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 사용하는 라이브러리와 버전 확인하기\n","!pip list"],"metadata":{"id":"Ef1M_pxR0rCZ"},"execution_count":null,"outputs":[]}]}