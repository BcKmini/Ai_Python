{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#**RAG Chatbot 정답**\n","#### **PDF 파일의 정보를 추출하고 RAG 기법을 사용하여 이 정보를 LLM이 활용하는 챗봇 만들기**"],"metadata":{"id":"hVzYd_OY0B7W"}},{"cell_type":"markdown","source":["##**1. 환경 준비**"],"metadata":{"id":"hRH8NNb7jjh4"}},{"cell_type":"markdown","source":["#### (1) 구글 드라이브 연결"],"metadata":{"id":"B-Ste0-ij1SR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bknf5IL_sLuJ"},"outputs":[],"source":["# 구글 드라이브를 코랩 환경에 연결하여 파일을 저장하거나 읽을 수 있도록 설정\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#### (2) 라이브러리 설치"],"metadata":{"id":"oMhy5LjDkD6i"}},{"cell_type":"code","source":["!pip install streamlit -q\n","!pip install pyngrok -q\n","!pip install openai -q\n","!pip install langchain -q\n","!pip install -U langchain-community -q\n","!pip install sentence-transformers -q\n","!pip install faiss-gpu -q\n","!pip install pyPDF2 -q"],"metadata":{"id":"ghrkopImsLuJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**2. 코딩**"],"metadata":{"id":"QQ1em3XukUiQ"}},{"cell_type":"code","source":["# 이 파일에 Streamlit 애플리케이션 코드를 작성\n","# 코드 수정 후, 셀을 실행해야 변경된 내용이 ooo.py 파일이 적용됨\n","%%writefile /content/drive/MyDrive/Streamlit/6-3.RAGChatbot.py\n","\n","# 라이브러리 불러오기\n","import streamlit as st\n","from PyPDF2 import PdfReader\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.embeddings import OpenAIEmbeddings, SentenceTransformerEmbeddings\n","from langchain.vectorstores import FAISS\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n","from langchain.memory import ConversationBufferWindowMemory\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# PDF 문서에서 텍스트 추출 함수 정의하기\n","def get_pdf_text(pdf_docs):\n","    text = \"\"\n","    for pdf in pdf_docs:\n","        pdf_reader = PdfReader(pdf)\n","        for page in pdf_reader.pages:\n","            text += page.extract_text()\n","    return text\n","\n","# 텍스트 분할 함수 정의하기\n","def get_text_chunks(text):\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        separators=\"\\\\n\",\n","        chunk_size=1000,\n","        chunk_overlap=200,\n","        length_function=len\n","    )\n","    chunks = text_splitter.split_text(text)\n","    return chunks\n","\n","# 임베딩 생성 & 벡터 저장소 생성 함수 정의하기\n","def get_vectorstore(text_chunks):\n","    embeddings = SentenceTransformerEmbeddings(model_name='all-MiniLM-L6-v2')\n","    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n","    return vectorstore\n","\n","# openai 키 입력\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxx\"\n","\n","# 주어진 벡터 저장소로 대화 체인 생성 함수 정의하기\n","def get_conversation_chain(vectorstore):\n","    memory = ConversationBufferWindowMemory(memory_key='chat_history', return_message=True)\n","    conversation_chain = ConversationalRetrievalChain.from_llm(\n","        llm=ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo-16k'),\n","        retriever=vectorstore.as_retriever(),\n","        get_chat_history=lambda h: h,\n","        memory=memory\n","    )\n","    return conversation_chain\n","\n","# PDF 파일을 업로드하고 텍스트를 추출하여 AI 대화 준비하기\n","user_uploads = st.file_uploader(\"파일을 업로드해주세요~\", accept_multiple_files=True)\n","if st.button(\"Upload\"):\n","    with st.spinner(\"처리중..\"):\n","        raw_text = get_pdf_text(user_uploads)\n","        text_chunks = get_text_chunks(raw_text)\n","        vectorstore = get_vectorstore(text_chunks)\n","        st.session_state.conversation = get_conversation_chain(vectorstore)\n","\n","# 사용자의 질문에 AI가 답변하기\n","if user_query := st.chat_input(\"질문을 입력해주세요~\"):\n","    if 'conversation' in st.session_state:\n","        result = st.session_state.conversation({\n","            \"question\": user_query,\n","            \"chat_history\": st.session_state.get('chat_history', [])\n","        })\n","        response = result[\"answer\"]\n","    else:\n","        response = \"먼저 문서를 업로드해주세요~.\"\n","    with st.chat_message(\"assistant\"):\n","        st.write(response)"],"metadata":{"id":"-090Z7oHKkEe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**3. Streamlit 실행**\n","* **ngrok 인증 토큰 받는 방법**\n","    * ngrok.com 사이트 가입 (Sign up)\n","    * 좌측 Getting Started > Your Authtoken 메뉴 선택하여 토큰 번호 받음\n","    * ngrok은 인터넷으로 터널을 만들어 로컬 개발 환경의 포트를 개방하고 애플리케이션의 외부 접근을 도와주는 터널 프로그램\n","*   **ooo.py 파일을 수정했는 데 이전 결과가 그대로 나타남**  \n","    * 코드 수정 후, 셀을 실행해야 변경된 내용이 ooo.py 파일이 적용됨\n","\n","* **아래 셀 실행결과가 아래와 같이 나타나면 좌측 url 주소(& <U>Visit Site 버튼</U> 클릭) 선택하여 결과 확인**\n","    * NgrokTunnel: \"https://5c10-34-86-195-94.ngrok-free.app\" -> \"http://localhost:8501\""],"metadata":{"id":"IJ0kr5inr0Gn"}},{"cell_type":"code","source":["from pyngrok import ngrok\n","\n","# ngrok 인증 토큰을 설정\n","ngrok.set_auth_token(\"ngrok 인증토큰번호를 입력하세요\")\n","\n","# Streamlit 애플리케이션을 백그라운드에서 실행\n","# ngrok을 통해 외부에서 접근 가능한 URL을 생성\n","!streamlit run /content/drive/MyDrive/Streamlit/6-3.RAGChatbot.py&>/dev/null&\n","url = ngrok.connect( addr='8501' )\n","print(url)"],"metadata":{"id":"Q76Q9fuhbhqD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**참조)**"],"metadata":{"id":"fniWUPvbr4Bg"}},{"cell_type":"code","source":["# 실행 중인 세션 확인\n","!ps"],"metadata":{"id":"8EhoB-Kir4Bh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 사용하는 라이브러리와 버전 확인하기\n","!pip list"],"metadata":{"id":"Ef1M_pxR0rCZ"},"execution_count":null,"outputs":[]}]}