{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝  프레임워크  DeepLearning Framework\n",
    "• ### 프레임워크(framework)\n",
    "⁻   응용 프로그램을 개발하기 위한 여러 라이브러리나 모듈 등을 효율적으로 사용할 수 있도록 하나로 \n",
    "묶어 놓은 일종의 패키지\n",
    "• 딥러닝 프레임워크 종류\n",
    "⁻   TensorFlow, Keras, Theano, PyTorch, CNTK, Caffe, Mxnet, DL4J  등\n",
    "\n",
    "### TensorFlow (Google)\n",
    "장점 : \n",
    "• 모델 세부 튜닝이 가능하여 디테일한 모델 설정 가능 \n",
    "• 거의 모든 딥러닝 프로젝트 에 범용적으로 활용 가능\n",
    "• 텐서보드를 통한 시각화\n",
    "단점 : \n",
    "• 저수준 모델링 \n",
    "= 높은 난이도\n",
    "#### PyTorch (Meta)\n",
    "장점 : \n",
    "• 익히기 쉽고 간결, 구현 빠름\n",
    "• 비교적 빠른 최적화 가능\n",
    "• 학습속도 빠름\n",
    "• Visdom을 통한 시각화\n",
    "단점 : \n",
    "• 텐서플로우에 비해 디테일한 \n",
    "모델링 불가능\n",
    "• 아직은 텐서플로우에 비해 부 \n",
    "족한 사용자 수\n",
    "\n",
    "#### Keras -> TensorFlow에 합쳐짐\n",
    "장점 : \n",
    "• 사용자 친화성, 모듈성, 확장성\n",
    "• 일관되고 간결한 API 제공\n",
    "• 배우기 쉽고 모델 구축이 쉬움\n",
    "단점 : \n",
    "• 함수 대부분 자동화 및 간편화 \n",
    "되어 딥러닝 구조 파악 어려움\n",
    "• 오류가 발생했을 때 케라스 자 \n",
    "체의 문제인지, 백엔드 언어의 \n",
    "문제인지 특정하기 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우  TensorFlow\n",
    "• 텐서플로우(TensorFlow)\n",
    "⁻   구글의 딥러닝 프레임워크, 내부적으로 C/C++로 구현\n",
    "⁻   파이썬 등 여러 가지 언어에서 접근할 수 있는 인터페이스 제공 \n",
    "⁻   텐서(tensor)는 물리학에서 다차원 배열을 나타내는 용어\n",
    "• 스칼라, 벡터, 행렬, 텐서 모두 지원 \n",
    "⁻   플로우(flow)는 흐름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "• Keras\n",
    "⁻   Python으로 작성\n",
    "⁻   TensorFlow, CNTK, Theano에서 실행할 수 있는 \n",
    "고수준 딥러닝 API\n",
    "⁻   쉽고 빠른 프로토타이핑이 가능\n",
    "⁻   순방향 신경망, 컨볼루션 신경망과 반복적인 신경망 외 여러 가지의 조합도 지원 \n",
    "⁻   CPU 및 GPU에서 원활하게 실행\n",
    "⁻   Tensorflow 2.0 버전 이상에는 Keras가 포함되어 있음 \n",
    "⁻   Keras는 신경망을 레고 조립하듯이 만들 수 있음\n",
    "\n",
    "• 설치 방법:\n",
    "⁻   pip install tensorflow      (CPU 버전)\n",
    "⁻   pip install tensorflow-gpu  (GPU 버전, 이는 CUDA 등 추가로 설치해야 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras를  이용한  다층  퍼셉트론  구현\n",
    "from tensorflow.keras.models import Sequential # -> Sequential -> 순차적인\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential() \n",
    "\n",
    "#모델 생성\n",
    "model.add(Dense(units=64, activation='sigmoid', input_dim=100)) \n",
    "model.add(Dense(units=10, activation='sigmoid')) #Dense -> 완전연결 구조\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=5, batch_size=32)\n",
    "\n",
    "loss_and_metrics = model.evaluate(X, y, batch_size=128)\n",
    "classes = model.predict(new_X, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1811 - loss: 0.0973\n",
      "Epoch 2/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3938 - loss: 0.0855\n",
      "Epoch 3/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5106 - loss: 0.0801\n",
      "Epoch 4/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5957 - loss: 0.0735\n",
      "Epoch 5/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6670 - loss: 0.0672\n",
      "Epoch 6/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7085 - loss: 0.0616\n",
      "Epoch 7/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7427 - loss: 0.0565\n",
      "Epoch 8/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7674 - loss: 0.0527\n",
      "Epoch 9/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7838 - loss: 0.0495\n",
      "Epoch 10/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8014 - loss: 0.0464\n",
      "Epoch 11/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8131 - loss: 0.0440\n",
      "Epoch 12/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8227 - loss: 0.0423\n",
      "Epoch 13/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 0.0404\n",
      "Epoch 14/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.0390\n",
      "Epoch 15/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8390 - loss: 0.0376\n",
      "Epoch 16/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.0364\n",
      "Epoch 17/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.0353\n",
      "Epoch 18/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8495 - loss: 0.0344\n",
      "Epoch 19/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.0336\n",
      "Epoch 20/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8524 - loss: 0.0328\n",
      "Epoch 21/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8567 - loss: 0.0320\n",
      "Epoch 22/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8588 - loss: 0.0314\n",
      "Epoch 23/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.0307\n",
      "Epoch 24/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.0301\n",
      "Epoch 25/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8638 - loss: 0.0297\n",
      "Epoch 26/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.0291\n",
      "Epoch 27/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.0288\n",
      "Epoch 28/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.0282\n",
      "Epoch 29/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8664 - loss: 0.0279\n",
      "Epoch 30/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8699 - loss: 0.0275\n",
      "Epoch 31/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8713 - loss: 0.0272\n",
      "Epoch 32/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8737 - loss: 0.0267\n",
      "Epoch 33/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8723 - loss: 0.0266\n",
      "Epoch 34/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8732 - loss: 0.0263\n",
      "Epoch 35/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.0260\n",
      "Epoch 36/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.0255\n",
      "Epoch 37/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8778 - loss: 0.0254\n",
      "Epoch 38/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8784 - loss: 0.0253\n",
      "Epoch 39/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.0250\n",
      "Epoch 40/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.0246\n",
      "Epoch 41/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.0247\n",
      "Epoch 42/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.0244\n",
      "Epoch 43/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8790 - loss: 0.0243\n",
      "Epoch 44/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8799 - loss: 0.0243\n",
      "Epoch 45/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.0239\n",
      "Epoch 46/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8823 - loss: 0.0237\n",
      "Epoch 47/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.0235\n",
      "Epoch 48/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.0235\n",
      "Epoch 49/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.0231\n",
      "Epoch 50/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.0233\n",
      "테스트 손실값: 0.022044643759727478\n",
      "테스트 정확도: 0.892799973487854\n"
     ]
    }
   ],
   "source": [
    "### [실습] MLP를 이용한  MNIST 숫자인식\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 128    #가중치를 변경하기 전에 처리하는 샘플의 개수 \n",
    "num_classes = 10    #출력 클래스의 개수\n",
    "epochs = 50\n",
    "\n",
    "#데이터를 학습 데이터와 테스트 데이터로 나눈다.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() \n",
    "\n",
    "#입력 이미지를 2차원에서 1차원 벡터로 변경한다.\n",
    "x_train = x_train.reshape(60000, 784) \n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "#입력 이미지의 픽셀 값이 0.0에서 1.0 사이의 값이 되게 한다. \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32') \n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#클래스의 개수에 따라서 하나의 출력 픽셀만이 1이 되게 한다. \n",
    "#예를 들면 1 0 0 0 0 0 0 0 0 0과 같다.\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes) \n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#신경망의 모델을 구축한다.\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "#구축한 신경망 모델 요약 출력 \n",
    "model.summary()\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "#손실 함수를 제곱 오차 함수로 설정하고 학습 알고리즘은 SGD 방식으로 한다. \n",
    "model.compile(loss='mean_squared_error',\n",
    "optimizer=sgd, \n",
    "metrics=['accuracy'])\n",
    "\n",
    "#학습을 수행한다.\n",
    "history = model.fit(x_train, y_train,\n",
    "batch_size=batch_size, \n",
    "epochs=epochs)\n",
    "\n",
    "#학습을 평가한다.\n",
    "score = model.evaluate(x_test, y_test, verbose=0) \n",
    "print('테스트 손실값:', score[0])\n",
    "print('테스트 정확도:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다층  퍼셉트론의  의의\n",
    "• 신경망의 기초적인 이론을 정립\n",
    "• 실용적인 성능\n",
    "⁻   1980~1990년대에 다층 퍼셉트론은 실용 시스템 제작에 크게 기여\n",
    "• 인쇄/필기 문자 인식으로 우편물 자동 분류기, 전표 인식기, 자동차 번호판 인식기 등\n",
    "• 음성 인식, 게임, 주가 예측, 정보 검색, 의료 진단, 유전자 검색, 반도체 결함 검사 등\n",
    "• 하지만 한계 노출\n",
    "⁻   잡음이 섞인 상황에서 음성인식 성능 저하 \n",
    "⁻   필기 주소 인식 능력 저하\n",
    "⁻   바둑에서의 한계\n",
    "⁻   딥러닝은 이를 극복함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 심층  신경망  DNN Deep Neural Network\n",
    "• DNN은 MLP(다층 퍼셉트론)에서 은닉층의 개수를 증가시킨 것\n",
    "• \"딥(deep)\"이라는 용어는 은닉층이 깊다는 것을 의미\n",
    "• 최근 딥러닝은 컴퓨터 시각, 음성 인식, 자연어 처리, 소셜 네트워크 필터링, 기계 \n",
    "번역 등에 적용되어서 인간 전문가에 필적하는 결과를 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝의  성공  요인\n",
    "• 다수의 은닉층을 가지는 MLP에서의 여러 가지 문제점을 효과적으로 해결\n",
    "• 문제점\n",
    "⁻   하드웨어 성능 문제 \n",
    "⁻   그래디언트 소멸 문제 \n",
    "⁻   손실 함수 문제\n",
    "⁻   가중치 초기화 문제 \n",
    "⁻   최적화 알고리즘 \n",
    "⁻   과대 적합 문제\n",
    "⁻   계산 시간 과다 등..\n",
    "\n",
    "### 하드웨어  성능  문제\n",
    "• DNN의 학습은 매우 계산 집약적이기 때문에 많은 시간과 자원이 많이 요구됨 → \n",
    "GPU(Graphic Processing Unit)를 이용하여 하드웨어적 한계를 극복\n",
    "\n",
    "\n",
    "• TPU(Tensor Processing Unit)\n",
    "⁻ 구글에서 2016년 5월에 발표한 데이터 분석 및 딥러닝용 하드웨어, 구글 자체 텐서플로우 소프트 웨어를 이용, 구글은 2015년에 내부적으로 TPU를 사용하기 시작, 2018년 서드파티용으로 판매 시작\n",
    "\n",
    "### 그래디언트  소멸  문제\n",
    "• 그래디언트 소멸 문제(gradient vanishing problem)\n",
    "⁻   특정 활성화 함수를 사용하는 계층이 신경망에 많이 추가되면 손실 함수의 그래디언트가 0에 가까 \n",
    "워져 학습이 되지 않는 현상\n",
    "⁻   역전파 학습 알고리즘은 각 층에서의 그래디언트를 이용하여 가중치를 수정\n",
    "\n",
    "\n",
    "### 원인: 시그모이드 활성화 함수\n",
    "⁻   아주 큰 양수나 아주 큰 음수가 들어오면 출력이 포화되어 기울기가 0에 수렴\n",
    "\n",
    "\n",
    "• 기존의 MLP는 시그모이드 함수를 활성화 함수로 사용 \n",
    "→ 새로운 활성화 함수 필요\n",
    "### ReLU\n",
    "⁻   f (x) = max(0, x)\n",
    "⁻   0 이상의 입력 값은 그대로 전달\n",
    "⁻   미분값은 0이나 1, 0에서는 미분 불가능 \n",
    "⁻   계산 간단하여 빠르게 계산 가능\n",
    "⁻   그래디언트 소멸 문제 완화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [실습] 활성화  함수  실험\n",
    "• 층을 깊게 하고 활성화 함수를 sigmoid로 설정하면?\n",
    "실습 사이트 : \n",
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.61151&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실  함수  문제\n",
    "• 지금까지 손실 함수로 평균 제곱 오차(Mean Squared Error: MSE) 사용\n",
    "\n",
    "• 손실 함수로 MSE, 노드의 활성화 함수 φ로 시그모이드 함수를 사용하면 저속 수렴 문제(slow convergence) 발생\n",
    "\n",
    "⁻   목표값 t=0.0, 출력값 z=10.0인 경우? 많이잘못되었다? -> 가중치를 많이 바꿈 \n",
    "⁻   목표값 t=0.0, 출력값 z=1.0인 경우?  조금잘못되었다? -> 가중치를 조금 바꿈\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 소프트맥스  활성화  함수\n",
    "• 해결방법: \n",
    "출력층 노드의 활성화 함수는 -> 소프트맥스(softmax) 함수, \n",
    "손실 함수는 -> 교차 엔트로피(cross entropy) 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차  엔트로피  손실  함수\n",
    "• 교차 엔트로피(cross entropy): 2개의 확률분포 간의 거리를 측정한 것 \n",
    "⁻   2개의 확률 분포 p(목표 출력), q(실제 출력)에 대해서 다음과 같이 정의\n",
    "\n",
    "⁻   교차 엔트로피가 크면, 2개의 확률 분포가 많이 다른 것, 작으면 2개의 확률 분포가 거의 일치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치  초기화  문제\n",
    "#### 가중치란? -> 얼마나 중요한지 설정해주는 값 \n",
    "• 가중치 초깃값에 따른 각 층의 활성화 값 분포 \n",
    "⁻   가중치를 표준편차가 1인 정규분포로 초기화할 때\n",
    "\n",
    "⁻   각 층의 활성화 값들이 0과 1에 치우쳐 분포 \n",
    "#### ⁻ 시그모이드 함수\n",
    "• 너무 크거나 작은 값이 들어오면 0과 1에 가까운 값 출력\n",
    "• 미분(기울기)는 0에 가까워 짐\n",
    "#### ⁻   기울기 소실(gradient vanishing) 문제 발생\n",
    "• 층이 깊은 딥러닝에서는 더 심각한 문제\n",
    "\n",
    "w = np.random.randn(node_num, node_num) * 1\n",
    "↓\n",
    "w = np.random.randn(node_num, node_num) * 0.1\n",
    "\n",
    "⁻   각 층의 활성화 값들이 0.5 부근에 집중 → 기울기 소실은 없으나 표현력이 제한됨\n",
    "• 다수의 뉴런이 비슷한 값을 출력하면 뉴런을 여러 개 둔 의미가 없어 짐\n",
    "• 각 층의 활성화 값은 적당히 고루 분포되어 있어야 이상적\n",
    "\n",
    "### Xavier 초깃값\n",
    "⁻   딥러닝 프레임워크에서 널리 사용되고 있는 가중치 초깃값 설정 방법\n",
    "⁻   각 층의 활성화 값들을 광범위하게 분포시킬 목적으로 가중치의 적절한 분포를 찾고자 함 \n",
    "⁻   앞 계층의 노드가 n개라면 표준편차가 1/sqrt(n)인 분포를 사용\n",
    "\n",
    "node_num = 100  # 앞 층의 노드 수\n",
    "w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n",
    "⁻   Xavier 초기값을 이용할 때의 각 층의 활성화값 분포\n",
    "\n",
    "⁻   활성화값이 넓게 분포 → 신경망의 표현력 증가 → 학습 성능 향상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치  초기화  방법\n",
    "•  ReLU를 활성화 함수로 할 때 \n",
    "가중치 초깃값에 따른 \n",
    "활성화 값 분포\n",
    "⁻   표준편차 0.01\n",
    "• 각 층의 활성화 값이 아주 작은 값\n",
    "→ 역전파 때 가중치의 기울기도 작아짐 \n",
    "→ 학습이 이루어지지 않음\n",
    "⁻   Xavier 초깃값\n",
    "• 층이 깊어지면서 치우침이 커짐 \n",
    "→ 기울기 소실 문제 발생\n",
    "⁻   He 초깃값\n",
    "• 모든 층에서 균일하게 분포 \n",
    "→ 역전파에서도 적절한 값 발생\n",
    "•  현재의 모범 사례\n",
    "⁻   ReLU에는 He 초깃값 사용\n",
    "⁻   sigmoid, tanh 등의 S자 함수에는 \n",
    "Xavier 초깃값 사용\n",
    "\n",
    "### [실습] 가중치  초기화  실험\n",
    "• https://www.deeplearning.ai/ai-notes/initialization/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니  배치  Mini-batch\n",
    "• 확률적 경사 하강법(Stochastic Gradient Descent, SGD) = 온라인 학습 \n",
    "⁻   하나의 샘플이 주어지면 오차를 계산하여서 바로 가중치를 변경하는 방법\n",
    "• 배치 학습(batch learning)\n",
    "⁻   모든 샘플을 모두 보여준 후에 개별 샘플의 그래디언트를 전부 더해서 이것을 바탕으로 모델의 가 \n",
    "중치를 변경하는 방법\n",
    "\n",
    "### 미니  배치  Mini-batch\n",
    "• 온라인 학습과 배치 학습의 중간에 있는 방법이 미니 배치\n",
    "⁻   훈련 데이터를 작은 배치들로 분리시켜서 하나의 배치가 끝날 때마다 학습을 수행하는 방법\n",
    "• 1(온라인) < size(매니 배치) < size(훈련 데이터)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화  알고리즘  Optimization Algorithm\n",
    "• 학습률(learning rate)\n",
    "⁻   한 번에 가중치를 얼마나 변경할 것인가를 결정 \n",
    "⁻   적절한 학습률은 어떻게 설정할 것인가?\n",
    "\n",
    "⁻   모든 파라미터에 같은 학습률을 사용할 것인가?\n",
    "⁻ 지역적 최소값(local minima)에서 어떻게 벗어날 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모멘텀  Momentum\n",
    "• 모멘텀(momentum)\n",
    "⁻   ‘운동량’을 뜻하는 단어, 기울기 방향으로 물체가 힘을 받아 가속된다는 물리 법칙\n",
    "⁻   학습 속도를 가속시킬 목적으로 사용 ex -> 가중치의 변화가 많이 되고 있으면 더 많이 가중치를 변화 시키도록 유도\n",
    "⁻   지역적 최소 문제 해결에도 도움이 됨\n",
    "\n",
    "• 모멘텀에 의한 최적화 갱신 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaGrad\n",
    "• 신경망 학습에서 학습률\n",
    "⁻   너무 작으면 학습 시간이 길어지고, 너무 크면 발산하여 학습 불가\n",
    "• 학습률 감소(learning rate decay)\n",
    "⁻   학습을 진행하면서 서서히 학습률을 줄여가는 방법 \n",
    "⁻   실제로 신경망 학습에서 자주 쓰임\n",
    "⁻   매개변수 전체의 학습률 값을 일괄적으로 낮추는 방법\n",
    "• AdaGrad (Adaptive Gradient)\n",
    "⁻   매개변수 각각의 학습률을 적응적으로 조정하는 방법\n",
    "\n",
    "### AdaGrad 갱신 방법\n",
    "\n",
    "⁻   h: 기존 기울기 값을 제곱하여 계속 더해줌,     : 행렬의 원소별 곱셈(element-wise) \n",
    "⁻   h는 기울기가 클수록 커짐, 기울기가 크다는 것은 갱신이 많이 되었다는 것\n",
    "⁻   즉, 크게 갱신된 원소의 학습률은 낮아짐\n",
    "\n",
    "• AdaGrad의 단점\n",
    "⁻   과거의 기울기를 제곱하여 계속 더해가기 때문에 학습이 진행될수록 갱신 강도가 약해짐 \n",
    "⁻   실제로 무한히 계속 학습한다면 갱신량은 0에 수렴하여 전혀 갱신되지 않음\n",
    "• RMSProp\n",
    "⁻   AdaGrad 단점 개선, 먼 과거의 기울기는 서서히 잊고 새로운 기울기 정보를 크게 반영\n",
    "⁻   지수이동평균(EMA; Exponential Moving Average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화  알고리즘\n",
    "• 모든 문제에서 항상 뛰어난 기법은 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과대  적합  Overfitting\n",
    "• 과대 적합(overfitting)\n",
    "⁻   모델이 학습 데이터에 특화되어 실제 데이터에서는 좋지 못한 결과가 나오는 현상\n",
    "\n",
    "### 규제항의 도입(regularization) \n",
    "⁻   은닉층 수가 많아지거나 가중치가 너무 복잡해지면 과대 적합 발생\n",
    "\n",
    "### 데이터 증강(data augmentation)\n",
    "⁻   데이터가 부족할 때, 유사한 데이터를 생성하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드롭  아웃  Drop out\n",
    "• 드롭 아웃(drop out) \n",
    "⁻   학습 과정에서 몇 개의 노드들을 랜덤하게 제외하는 것\n",
    "⁻   제외된 노드를 대신해서 다른 노드들이 특정 데이터를 학습\n",
    "⁻   해당 데이터에 대한 특징을 많은 노드들이 학습할 수 있도록 유도 \n",
    "-> 오버피팅을 피하고 결과값이 더 좋아지는 결과가 나온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8932 - loss: 0.3610\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9691 - loss: 0.0984\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.0699\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0495\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0365\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.9757 - loss: 0.0828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06786450743675232, 0.9793999791145325]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the input data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(x_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
